---
title: "LDA"
output:
  word_document: default
  html_notebook: default
---



```{r}
library(tm)
library(topicmodels)
library(tidyverse)
library(tidytext)
library(slam)

```

```{r}
importdf = read.csv('dftxt.csv', header = F, stringsAsFactors = F)
```

```{r}
import_corpus = Corpus(VectorSource(importdf))
```

```{r}
import_mat = 
  DocumentTermMatrix(import_corpus,
           control = list(stemming = TRUE, #create root words
                          stopwords = TRUE, #remove stop words
                          minWordLength = 3, #cut out small words
                          removeNumbers = TRUE, #take out the numbers
                          removePunctuation = TRUE)) #take out punctuation 
```

```{r}
import_weight = tapply(import_mat$v/row_sums(import_mat)[import_mat$i], 
                       import_mat$j, 
                       mean) *
  log2(nDocs(import_mat)/col_sums(import_mat > 0))

#ignore very frequent and 0 terms
import_mat = import_mat[ , import_weight >= .1]
import_mat = import_mat[ row_sums(import_mat) > 0, ]
```

```{r}
k = 5 #set the number of topics

SEED = 2010 #set a random number 

LDA_fit = LDA(import_mat, k = k, 
              control = list(seed = SEED))

LDA_fixed = LDA(import_mat, k = k, 
                control = list(estimate.alpha = FALSE, seed = SEED))
```

```{r}
LDA_gibbs = LDA(import_mat, k = k, method = "Gibbs", 
                control = list(seed = SEED, burnin = 1000, 
                               thin = 100, iter = 1000))

CTM_fit = CTM(import_mat, k = k, 
              control = list(seed = SEED, 
                             var = list(tol = 10^-4), 
                             em = list(tol = 10^-3)))
```
```{r}
LDA_fit@alpha
```

```{r}
LDA_fixed@alpha
```

```{r}
LDA_gibbs@alpha
```

```{r}
sapply(list(LDA_fit, LDA_fixed, LDA_gibbs, CTM_fit), 
       function (x) 
         mean(apply(posterior(x)$topics, 1, function(z) - sum(z * log(z)))))
```
```{r}
topics(LDA_fit, k)
```

```{r}
terms(LDA_fit,5)
```
```{r}
terms(LDA_gibbs,5)
```
```{r}
#use tidyverse to clean up the the fit     
LDA_fit_topics = tidy(LDA_fit, matrix = "beta")

#create a top terms 
top_terms = LDA_fit_topics %>%
   group_by(topic) %>%
   top_n(10, beta) %>%
   ungroup() %>%
   arrange(topic, -beta)
```

```{r}
cleanup = theme(panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(), 
                panel.background = element_blank(), 
                axis.line.x = element_line(color = "black"),
                axis.line.y = element_line(color = "black"),
                legend.key = element_rect(fill = "white"),
                text = element_text(size = 10))
```

```{r}
#make the plot
top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  cleanup +
  coord_flip()
```






